{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class Auto_model():\n",
    "     \n",
    "    def __init__(self,path,target):\n",
    "        \n",
    "        self.df = pd.read_csv(path)\n",
    "        self.target = target\n",
    "        \n",
    "        self.models_param = {'REG_LOG' :{'penalty' : ['l1', 'l2']},\n",
    "                            'XGBOOST':{'min_child_weight': [1, 5, 10],'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "                                       'subsample': [0.6, 0.8, 1.0],'colsample_bytree': [0.6, 0.8, 1.0],'max_depth': [3, 4, 5]},\n",
    "                           \n",
    "                            'GBOOST': {'n_estimators':  [10, 50, 100, 200], 'learning_rate': [0.01, 0.1, 1],\n",
    "                                       'max_depth': [1, 2]},\n",
    "                                       \n",
    "                            'SVM_RBF': {'kernel': ['rbf'],'C': [0.01,0.1,1, 10, 50, 100, 500, 1000], \n",
    "                                    'gamma': ['auto',0.1, 1, 5, 10, 50,'auto_deprecated']},\n",
    "                             \n",
    "                            'RANDOM_FOREST': {'n_estimators':  [1,10], 'criterion': ['entropy', 'gini'], \n",
    "                                   'max_depth': [1, 2], 'max_features': ['auto']},\n",
    "                             \n",
    "                            'ADABOOST': {'n_estimators':  [10, 50, 100, 200], 'learning_rate': [0.1, 1, 10]}\n",
    "}\n",
    "\n",
    "     \n",
    "               \n",
    "        self.models_grid = {}\n",
    "        self.models_grid['REG_LOG'] = GridSearchCV(LogisticRegression(random_state=0),self.models_param['REG_LOG'] ,\n",
    "                                             scoring='accuracy', verbose=True)\n",
    "        self.models_grid['XGBOOST'] = GridSearchCV(XGBClassifier(random_state=0),self.models_param['XGBOOST'], \n",
    "                                              scoring='accuracy', verbose=True)\n",
    "        self.models_grid['GBOOST'] = GridSearchCV(GradientBoostingClassifier(random_state=0),self.models_param['GBOOST'],\n",
    "                                             scoring='accuracy', verbose=True)\n",
    "        self.models_grid['SVM_RBF'] = GridSearchCV(SVC(kernel='rbf',random_state=0),self.models_param['SVM_RBF'],\n",
    "                                          scoring='accuracy', verbose=True)\n",
    "        self.models_grid['RANDOM_FOREST'] = GridSearchCV(RandomForestClassifier(random_state=0),\n",
    "                                                self.models_param['RANDOM_FOREST'],scoring='accuracy', verbose=True)\n",
    "        \n",
    "        self.models_grid['ADABOOST'] = GridSearchCV(AdaBoostClassifier(random_state=0),self.models_param['ADABOOST'],\n",
    "                                               scoring='accuracy', verbose=True)\n",
    "  \n",
    "        self.models = {}\n",
    "        self.models['REG_LOG'] = LogisticRegression(random_state=0)\n",
    "        self.models['XGBOOST'] = XGBClassifier(random_state=0)\n",
    "        self.models['GBOOST'] = GradientBoostingClassifier(random_state=0)\n",
    "        self.models['SVM_RBF'] = SVC(kernel='rbf',random_state=0)\n",
    "        self.models['RANDOM_FOREST'] = RandomForestClassifier(random_state=0)                                 \n",
    "        self.models['ADABOOST'] = AdaBoostClassifier(random_state=0)\n",
    "        \n",
    "    def preprocess(self):\n",
    "\n",
    "        taille = self.df.shape\n",
    "        \n",
    "        for column in self.df.columns:\n",
    "            if self.df[column].isnull().sum()/taille[0] > 0.2:\n",
    "                self.df.drop([column], inplace=True, axis=1)\n",
    "\n",
    "        self.df.dropna(axis=0, inplace=True)\n",
    "\n",
    "        y = self.df[self.target]\n",
    "        X = self.df.drop([self.target], axis=1)\n",
    "\n",
    "        for column in X.columns:\n",
    "            try:\n",
    "                pd.to_numeric(X[column])\n",
    "            except ValueError:\n",
    "                dummies = pd.get_dummies(X[column], drop_first=True)\n",
    "                X = pd.concat([X, dummies], axis=1)\n",
    "                X.drop([column], inplace=True, axis=1)\n",
    "                \n",
    "                \n",
    "                \n",
    "        return train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "   \n",
    "    \n",
    "        \n",
    "    def fit(self,X,y,grid_search = True):\n",
    "        if grid_search:\n",
    "            \n",
    "            for model in self.models_grid:\n",
    "        \n",
    "                self.models_grid[model].fit(X,y).best_estimator_\n",
    "        else:\n",
    "            \n",
    "            for model in self.models:\n",
    "                self.models[model].fit(X,y)\n",
    "        self.grid_search = grid_search\n",
    "             \n",
    "    \n",
    "    def predict(self,X):\n",
    "        predict_dic = {}\n",
    "        if self.grid_search:\n",
    "            for model in self.models_grid:\n",
    "                predict_dic[model] = self.models_grid[model].predict(X)\n",
    "            return predict_dic\n",
    "        else:\n",
    "            for model in self.models:\n",
    "                predict_dic[model] = self.models[model].predict(X)\n",
    "            return predict_dic\n",
    "                \n",
    "            \n",
    "            \n",
    "\n",
    "    def accuracy_ml(self,y,y_pred):\n",
    "        accuracy_dict = {}\n",
    "        if self.grid_search:\n",
    "            for model in self.models_grid:\n",
    "                accuracy_dict[model] = accuracy_score(y_pred[model], y) \n",
    "            #self.accuracy_dict =accuracy_dict[model]\n",
    "            return accuracy_dict\n",
    "        else:\n",
    "            for model in self.models:\n",
    "                accuracy_dict[model] = accuracy_score(y_pred[model], y) \n",
    "            #self.accuracy_dict =accuracy_dict[model]\n",
    "            return accuracy_dict\n",
    "    \n",
    "    def f1score_ml(self,y,y_pred):\n",
    "        f1_score_dict = {}\n",
    "        if self.grid_search:\n",
    "            for model in self.models_grid:\n",
    "                f1_score_dict[model] = f1_score(y_pred[model], y,average='weighted') \n",
    "            return f1_score_dict\n",
    "        else:\n",
    "            for model in self.models:\n",
    "                f1_score_dict[model] = f1_score(y_pred[model], y,average='weighted') \n",
    "            return f1_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = Auto_model(path = \"Social_Network_Ads.csv\", target = 'Purchased', )\n",
    "X_train, X_test, y_train, y_test = models.preprocess()\n",
    "models.fit(X_train,y_train,grid_search=False)\n",
    "accuracy_test = models.accuracy_ml(y_test, models.predict(X_test))\n",
    "fscore = models.f1score_ml(y_test, models.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'REG_LOG': 0.825,\n",
       " 'XGBOOST': 0.9375,\n",
       " 'GBOOST': 0.925,\n",
       " 'SVM_RBF': 0.725,\n",
       " 'RANDOM_FOREST': 0.9125,\n",
       " 'ADABOOST': 0.925}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'REG_LOG': 0.8437908496732026,\n",
       " 'XGBOOST': 0.9370772946859903,\n",
       " 'GBOOST': 0.9240274599542335,\n",
       " 'SVM_RBF': 0.8405797101449275,\n",
       " 'RANDOM_FOREST': 0.9131435102365334,\n",
       " 'ADABOOST': 0.9261501210653755}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
